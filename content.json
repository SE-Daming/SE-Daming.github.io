{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"https://se-daming.github.io","root":"/"},"pages":[],"posts":[{"title":"test3.md","slug":"test3-md","date":"2024-11-23T14:12:51.000Z","updated":"2024-10-13T14:35:20.634Z","comments":true,"path":"2024/11/23/test3-md/","permalink":"https://se-daming.github.io/2024/11/23/test3-md/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"snow1","slug":"snow1","date":"2024-10-13T15:17:33.000Z","updated":"2024-10-13T15:17:33.136Z","comments":true,"path":"2024/10/13/snow1/","permalink":"https://se-daming.github.io/2024/10/13/snow1/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"test8.md","slug":"test8-md","date":"2024-10-13T14:13:22.000Z","updated":"2024-10-13T14:13:22.318Z","comments":true,"path":"2024/10/13/test8-md/","permalink":"https://se-daming.github.io/2024/10/13/test8-md/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"test7.md","slug":"test7-md","date":"2024-10-13T14:13:16.000Z","updated":"2024-10-13T14:13:16.983Z","comments":true,"path":"2024/10/13/test7-md/","permalink":"https://se-daming.github.io/2024/10/13/test7-md/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"test6.md","slug":"test6-md","date":"2024-10-13T14:13:12.000Z","updated":"2024-10-13T14:13:12.040Z","comments":true,"path":"2024/10/13/test6-md/","permalink":"https://se-daming.github.io/2024/10/13/test6-md/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"test5.md","slug":"test5-md","date":"2024-10-13T14:13:06.000Z","updated":"2024-10-13T14:13:06.449Z","comments":true,"path":"2024/10/13/test5-md/","permalink":"https://se-daming.github.io/2024/10/13/test5-md/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"test4.md","slug":"test4-md","date":"2024-10-13T14:13:01.000Z","updated":"2024-10-13T14:13:01.218Z","comments":true,"path":"2024/10/13/test4-md/","permalink":"https://se-daming.github.io/2024/10/13/test4-md/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"test.md","slug":"test-md","date":"2024-10-13T14:08:46.000Z","updated":"2024-10-13T14:09:07.593Z","comments":true,"path":"2024/10/13/test-md/","permalink":"https://se-daming.github.io/2024/10/13/test-md/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"面试题","slug":"面试题","date":"2024-10-13T08:24:58.000Z","updated":"2024-10-13T14:31:00.074Z","comments":true,"path":"2024/10/13/面试题/","permalink":"https://se-daming.github.io/2024/10/13/%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"","text":"面试题总结juc线程池参数、拒绝策略 :star:A：核心线程数、最大线程数、最大空余时间、时间单位、阻塞队列、线程工厂、拒绝策略 拒绝策略：Abort（默认、抛异常）、CallerRuns（调用提交方法的线程执行）、Discard（抛弃该任务）、DiscardOldest allowCoreThreadTimeOut(true)，核心线程在超出 keepAliveTime 后可以被销毁， 核心线程数设置cpu密集型：cpu+1 io密集型：2*cpu+1 线程池的好处降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 死锁如何解决 :star:没出现前：避免使用多个锁、按顺序获得锁、锁超时释放机制 出现后：死锁的检测机制、工具检测jstack、jconsole 死锁产生的条件和避免四个条件：互斥、请求与保持、不可抢占、循环等待 避免：破坏这四个条件 Synchronized和ReentrantLock的区别:star:sync可以修饰普通方法、静态方法、代码块自动释放锁，Rlock只能修饰代码块，手动释放锁 sync是重量级锁、Rlock是轻量级锁 sync是非公平锁、Rlock可以说非公平也可是公平 Rlock可以响应中断、sync不可以响应中断 sync是基于底层的监视器monitor实现的、Rlock是基于AQS实现的 Rlock可带超时的获取锁尝试 竞争不激烈时、sync的性能高于Rlock；激烈时、sync的性能大大降低 Rlock可结合condition选择性通知，更加灵活、sync只能通知同一个锁的等待队列 轻量级锁和重量级锁Synchronized锁升级 :star:无锁–&gt;偏向锁–&gt;轻量级锁–&gt;重量级锁 线程 A 进入 synchronized 开始抢锁，JVM 会判断当前是否是偏向锁的状态，如果是就会根据 Mark Word 中存储的线程 ID 来判断，当前线程 A 是否就是持有偏向锁的线程。如果是，则忽略 check，线程 A 直接执行临界区内的代码。 但如果 Mark Word 里的线程不是线程 A，就会通过自旋尝试获取锁，如果获取到了，就将 Mark Word 中的线程 ID 改为自己的；如果竞争失败，就会立马撤销偏向锁，膨胀为轻量级锁。 后续的竞争线程都会通过自旋来尝试获取锁，如果自旋成功那么锁的状态仍然是轻量级锁。然而如果竞争失败，锁会膨胀为重量级锁，后续等待的竞争的线程都会被阻塞。 Synchronized锁加粗volatile如何保证可见性:star:内存屏障、禁止指令重排 内存屏障（Memory Barrier）： 当一个线程写入一个 volatile 变量时，JVM 会在该写入操作前后插入内存屏障，确保写入操作不会与其他操作重排序，并且会强制将修改后的值刷新到主内存中。 当一个线程读取一个 volatile 变量时，JVM 也会在读取操作前插入内存屏障，确保读取操作不会与其他操作重排序，并且会从主内存中读取最新的值。 主内存与工作内存： 在 Java 中，每个线程都有自己的工作内存（Local Memory），而所有线程共享一个主内存（Main Memory）。 当一个线程对 volatile 变量进行写操作时，新的值会被立即写回到主内存中。 当一个线程对 volatile 变量进行读操作时，会从主内存中读取最新的值。 缓存一致性协议： 在多核处理器架构中，不同的 CPU 核心可能会缓存共享内存中的数据。为了保证 volatile 变量的可见性，处理器之间会使用缓存一致性协议。 当一个核心修改了某个 volatile 变量的值，它会通知其他核心该变量已更改，使得其他核心知道需要从主内存中重新加载该变量的最新值。 内存屏障内存屏障（Memory Barrier），也称为内存栅栏（Memory Fence），是一种硬件指令或编译器构造，用于控制处理器对内存操作的重排序，确保某些内存操作按照特定的顺序执行。内存屏障在并发编程和多线程环境下尤为重要，因为它们可以帮助确保数据的一致性和可见性。 内存屏障的作用内存屏障主要用于解决以下问题： 保证内存操作的顺序： 在没有内存屏障的情况下，编译器或处理器可能会为了优化性能而重新排序内存操作。内存屏障可以防止这种重排序，确保内存操作按照程序员预期的顺序执行。 确保数据的可见性： 在多线程或多处理器环境中，内存屏障可以确保一个线程对内存的修改能够被其他线程及时看到。这是因为内存屏障会强制将数据从高速缓存（Cache）写回到主内存中，并通知其他处理器该数据已更改。 保持数据一致性： 内存屏障还可以用来维持数据的一致性，防止数据竞争条件（Race Condition）的发生。 内存屏障的类型内存屏障通常分为以下几种类型： Load-Load Barrier： 保证所有前面的 Load 操作在任何后面的 Load 操作之前完成。 Store-Store Barrier： 保证所有前面的 Store 操作在任何后面的 Store 操作之前完成。 Load-Store Barrier： 保证所有前面的 Load 操作在任何后面的 Store 操作之前完成。 Store-Load Barrier： 保证所有前面的 Store 操作在任何后面的 Load 操作之前完成。 内存屏障在 Java 中的应用在 Java 中，内存屏障主要通过 volatile 关键字和 synchronized 关键字来实现。 volatile： 当一个变量被声明为 volatile 时，JVM 会在读取和写入该变量时插入适当的内存屏障。 读取 volatile 变量时，会插入一个 Load-Load Barrier，并且会从主内存中读取该变量的最新值。 写入 volatile 变量时，会插入一个 Store-Store Barrier，并且会将该变量的新值写回到主内存中。 synchronized： synchronized 关键字不仅提供了互斥访问（锁），还在进入和退出同步块时插入内存屏障。 进入 synchronized 块时，会插入一个 Store-Store Barrier，确保进入同步块之前的所有写操作已完成。 退出 synchronized 块时，会插入一个 Load-Load Barrier，确保所有读操作可以看到之前所有写操作的结果。 示例考虑以下 Java 代码： 1234567891011121314151617public class MemoryBarrierExample &#123; private volatile int x = 0; private volatile int y = 0; public void writeXThenY() &#123; x = 1; // 写入 x y = 1; // 写入 y &#125; public void readXAndY() &#123; int a = x; // 读取 x int b = y; // 读取 y if (a == 1 &amp;&amp; b == 1) &#123; System.out.println(&quot;Both x and y are set to 1.&quot;); &#125; &#125;&#125; 在这个例子中，如果 x 和 y 都被声明为 volatile，那么 writeXThenY 方法中的写入操作会插入适当的内存屏障，确保写入的顺序不会被重排序，并且写入的值能够被其他线程及时看到。同样，readXAndY 方法中的读取操作也会插入内存屏障，确保读取的顺序不会被重排序，并且读取的值是最新的。 总结内存屏障是并发编程中的一种重要机制，它通过确保内存操作的顺序性和可见性来维护数据的一致性。在 Java 中，volatile 和 synchronized 关键字的实现都依赖于内存屏障来实现其效果。理解内存屏障的工作原理有助于更好地设计和实现并发安全的程序。 volatile原理Synchronized锁实现原理:star:悲观锁、乐观锁、分布式锁区别:star:CompletableFuture是什么CompletableFuture如何进行异步编排ThreadLocal是个什么的ThreadLoacl是怎么回收的如何理解线程安全:star: 线程安全指的是在多线程环境下，对于同一份数据，不管有多少个线程同时访问，都能保证这份数据的正确性和一致性。 Java如何实现线程安全:star:线程同步：synchronized锁、reentrantlock锁、 cas volatile关键字 原子变量 final Lock底层Lock和Synchronized区别线程池如何实现线程的状态，状态之间如何转换线程创建的几种方式:star:继承Thread类重写run方法 实现Runnable接口的run方法 实习Callable接口的call方法，包装成futuretask传递给thread运行 线程池 什么是并发并行CAS锁 :star:cas是一种乐观锁的算法思想，主要用于更新操作他有三个核心参数：操作变量，原始值，预期值。当原始值操作后等于预期值则更新成功，否则重试直至更新成功 CAS自旋会占用cpu吗CountDownlatch怎么用CouurentHashMap如何保证线程安全的:star:分段锁优势读要不要并发控制Synchronized是轻量级锁还是重量级锁线程池对不断堆积任务的运行流程阻塞队列满了才启动备用线程吗核心线程会被回收吗？非核心线程呢？sleep和wait的区别:star:sleep()没有释放锁，而 wait() 方法释放了锁 。 wait() 通常被用于线程间交互&#x2F;通信，sleep()通常被用于暂停执行。 wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify()或者 notifyAll() 方法。sleep()方法执行完成后，线程会自动苏醒，或者也可以使用 wait(long timeout) 超时后线程会自动苏醒。 sleep() 是 Thread 类的静态本地方法，wait() 则是 Object 类的本地方法 wait为什么放在Object中拒绝策略什么时候触发semphore的原理，与线程池的区别线程变量分别用那个信号量和线程池的区别？线程池的状态？Runnable和Callable的区别:star:Runnable没有返回值、只是执行一段任务；Callable有返回值 Runnable执行任务时不会抛出异常，Callable会抛出异常 Callable执行完任务后通过future获取结果；runnable没结果 Callable获取返回值join的作用多线程间的通信机制有哪几种:star:1.volatile和synchronized关键字2.等待&#x2F;通知机制3.管道输入输出流4.join()[方法]5.ThreadLocal() 进程和线程的区别:star: 本质区别：进程是操作系统资源分配的基本单位，而线程是任务调度和执行的基本单位 在开销方面：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小 所处环境：在操作系统中能同时运行多个进程（程序）；而在同一个进程（程序）中有多个线程同时执行（通过CPU调度，在每个时间片中只有一个线程执行） 内存分配方面：系统在运行的时候会为每个进程分配不同的内存空间；而对线程而言，除了CPU外，系统不会为线程分配内存（线程所使用的资源来自其所属进程的资源），线程组之间只能共享资源 包含关系：没有线程的进程可以看做是单线程的，如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程 如何进行调度怎么样能让两个线程依次进行完，在进行其他操作介绍一下fork和join自旋锁的概念，应用场景ReentrantLock原理CountDownlatch原理线程安全的集合线程池的状态:star:Running、shutdown、stop、tidying、terminated 线程池的执行流程先判断当前线程数是否大于核心线程数？如果结果为 false，则新建线程并执行任务；如果结果为 true，则判断任务队列是否已满？如果结果为 false，则把任务添加到任务队列中等待线程执行，否则则判断当前线程数量是否超过最大线程数？如果结果为 false，则新建线程执行此任务，否则将执行线程池的拒绝策略 可重入锁和应用场景介绍AQSAQS原理CLH介绍读写锁读锁什么时候转化为写锁介绍一下LockJVMjvm内存区域可分为两大类：线程共享和线程隔离 线程共享的包括堆和方法区 线程隔离包括程序计数器、虚拟机栈、本地方法栈 堆：存放创建出来的对象实例 方法区：主要包含三个部分：类信息、运行时常量池、字符串常量池。（类信息、字段信息、方法信息、常量、静态变量） 其中类信息存储了InstanceKlass的字段、方法、虚方法表 运行时常量池存储编译期生成的各种字面量和符号引用 字符串常量池存储使用到的字符串 虚拟机栈：主要包含局部变量表、操作数栈、动态链接（当前类的字节码指令引用了其他类的属性或者方法时，需要将符号引用（编号）转换成对应的运行时常量池中的内存地址）、方法出口、异常表的引用（异常表存放的是代码中异常的处理信息，包含了异常捕获的生效范围以及异常发生后跳转到的字节码指令位置）； 程序计数器：记当前线程要执行的字节码的地址 类的生命周期加载、连接（验证、准备、解析）、初始化、使用、卸载 加载：根据全类名以二进制流的方式获取字节码文件 验证：检测字节码文件是否遵循《Java虚拟机规范》，主要包含：文件格式验证，主次版本号是否满足要求、元信息验证，必须有父类、验证程序执行指令的语义，方法区内的指令跳转到正确位置、符号引用验证，是否访问了其他类的private 准备：为类变量分配内存并在方法区初始化 解析：将常量池的符号引用替换成直接引用 初始化：执行clinit方法的字节码指令，包含静态代码块的代码，并为静态变量赋值；执行类的构造方法 使用 卸载：垃圾回收器回收 什么情况下初始化当遇到 new、 getstatic、putstatic 或 invokestatic 这 4 条字节码指令时，比如 new 一个类，读取一个静态字段(未被 final 修饰)、或调用一个类的静态方法时。 当 jvm 执行 new 指令时会初始化类。即当程序创建一个类的实例对象。 当 jvm 执行 getstatic 指令时会初始化类。即程序访问类的静态变量(不是静态常量，常量会被加载到运行时常量池)。 当 jvm 执行 putstatic 指令时会初始化类。即程序给类的静态变量赋值。 当 jvm 执行 invokestatic 指令时会初始化类。即程序调用类的静态方法。 使用 java.lang.reflect 包的方法对类进行反射调用时如 Class.forName(&quot;...&quot;), newInstance() 等等。如果类没初始化，需要触发其初始化。 初始化一个类，如果其父类还未初始化，则先触发该父类的初始化。 当虚拟机启动时，用户需要定义一个要执行的主类 (包含 main 方法的那个类)，虚拟机会先初始化这个类。 MethodHandle 和 VarHandle 可以看作是轻量级的反射调用机制，而要想使用这 2 个调用， 就必须先使用 findStaticVarHandle 来初始化要调用的类。 「补充，来自issue745open in new window」 当一个接口中定义了 JDK8 新加入的默认方法（被 default 关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化 类加载器分类及其范围启动类加载器：加载jre&#x2F;lib下的，比如比如rt.jar，tools.jar，resources.jar 扩展类加载器：加载lre&#x2F;lib&#x2F;ext下的 应用程序类加载器：加载classpath下的 打破双亲委派自定义类加载器并且重写loadClass方法。 计算机网络TCP重传超时重传、快重传 TCP拥塞控制涉及到两个变量cwnd、ssthresh(慢开始门限)： 首先慢开始 cwnd为1（MSS、最大报文段大小）、开始指数倍的增加、当增加到ssthreah时转而执行拥塞避免，当网络阻塞发生重传时，如果发生超时重传则把cwnd重置为1，ssthresh变为cwnd的一半，继续慢开始；如果发生快重传则执行快恢复拥塞算法，当收到三个重复的ACK时，把cwnd变为一半(+3),重传丢失的数据包，如果再收到重复的ACK则cwnd加1，如果收到新的ACK就把cwnd设为ssthresh，继续拥塞控制 慢开始、拥塞避免、快重传、快恢复 慢开始： 初始时，cwnd（拥塞窗口）设置为1个MSS（最大报文段大小）。 每当收到一个ACK，cwnd就增加一个MSS。 cwnd按指数增长，直到达到ssthresh（慢开始阈值）。 拥塞避免： 当cwnd达到ssthresh时，进入拥塞避免阶段。 在拥塞避免阶段，cwnd每次增加一个MSS，而不是成倍增加。 这样做是为了更缓慢地增加发送速率，以避免引起网络拥塞。 超时重传： 如果发生超时重传（即定时器超时），这通常意味着网络严重拥塞。 此时，将cwnd重置为1 MSS，并将ssthresh设置为当前cwnd的一半。 然后重新进入慢开始阶段。 快速重传： 如果接收到三个重复的ACK，这表明某个数据段很可能在网络中丢失。 此时不等待定时器超时，而是立即重传丢失的数据段。 快速恢复： 在快速重传之后，cwnd不是重置为1 MSS，而是设置为ssthresh加上最多三个MSS（因为收到了三个重复ACK）。 ssthresh此时设置为当前cwnd的一半。 每收到一个重复的ACK，cwnd增加一个MSS。 当收到一个非重复的ACK（即新数据的ACK）时，结束快速恢复阶段，cwnd设置为ssthresh，并进入拥塞避免阶段。 输入URL发生什么浏览器解析URL、生成HTTP请求信息； DNS查询域名对应的IP地址； 根据IP和端口向目标服务器发送TCP连接请求； 组装TCP报文、委托IP将报文封装成网络包，网络包还要在头部加上MAC地址； 建立好连接后发送HTTP请求报文； 服务端收到请求后发送响应报文、客户端解析出HTTP响应报文并渲染网页格式样式； 浏览器不需要通信时可以断开TCP连接 OSio多路复用有哪几种？区别集合ArrayList vs LinkedList设计一个线程安全的ArrayListList vs setHashMap线程安全问题 多线程下扩容会死循环（jdk7、jdk8已解决） 多线程下 put 会导致元素丢失 put时先计算对应hash下标是否为null、如果是null则put。A、B两线程同时判断条件成立后、A先创建newNode放入entry数组、B再创建放入，把A的覆盖了 put 和 get 并发时会导致 get 到 null ​ put时会创建一个newTable给table、然后再遍历旧table转存元素、此时还未来得及转存get旧table元素为null LinkedHashMap和HashMap的区别dk1.8之前hashmap插入时为啥使用头插法1、优化性能。头插法时间复杂度为O1，避免遍历整个链表 2、简化操作。简化了链表结构的维护。多线程环境下头插法避免了链表尾部可能需要的锁定或复杂操作，减少了并发操作对链表结构的影响。尤其在多线程环境中，需要考虑如何在遍历过程中避免并发修改的影响。头插法避免了这种复杂性。 3、头部可能比尾部更加容易被访问，可以提高数据的缓存局部性 Spring单例bean是线程安全的吗bean的生命周期 bean的生命周期大致分为四部分：实例化，属性赋值，初始化，销毁 实例化就是创建了一个bean对象、然后进行属性赋值，将bean的引用和值注入到属性中。 之后就是初始化，初始化阶段主要做了如下几个事情：先检查Aware的相关接口并设置相关依赖，比如如果实现了beanNameAware接口，就注入当前bean的beanName，如果实现了beanClassLoaderAware则注入加载当前bean的ClassLoader，如果实现了beanFactoryAware接口则注入当前beanFactory容器的引用。 如果bean实现了ApplicationContextAware接口，则调用setApplicationContext方法将bean所在的应用上下文引用传入进来 之后beanPostProcessor接口前置处理，调用其中的postProcessBeforeInitialization方法（作用比如为当前bean提供代理对象，AOP）。之后调用initializingBean接口中的afterPropertiesSet()方法。如果bean使用init-method方法声明了初始化方法则也会调用该方法，至此初始化完毕，bean准备就绪可以被应用程序使用了 最后是销毁，如果bean实现了DisposableBean接口，则调用destroy方法，同样如果bean使用了destroy-method声明销毁方法则也会被调用 事务隔离级别事务传播机制PROPAGATION_REQUIRED、 REQUIRED_NEW 、MANDATORY、 NESTED、 SUPPPORTS、 NOT_SUPPORTED、 NEVER 事务失效springboot自动装配原理sprigboot自动装配主要依赖核心注解springbootApplication，里面有一个注解EnableAutoConfiguration导入了一个叫AutoConfigurationImportSelector的bean 该bean实现了读取当前项目和引用项目jar包的classpath下META-INF下的spring factories文件中的类的全类名，在这些配置类中定义的bean会根据条件注解来决定是否需要导入到spring容器中 spring解决循环依赖、三级缓存singletonObject：一级缓存，存放完全实例化且属性赋值完成的 Bean ，可以直接使用earlySingletonObject：二级缓存，存放早期 Bean 的引用，尚未装配属性的 BeansingletonFactories：三级缓存，存放实例化完成的 Bean 工厂 如果发生循环依赖的话，就去 三级缓存 singletonFactories 中拿到三级缓存中存储的 ObjectFactory 并调用它的 getObject() 方法来获取这个循环依赖对象的前期暴露对象（虽然还没初始化完成，但是可以拿到该对象在堆中的存储地址了），并且将这个前期暴露对象放到二级缓存中，这样在循环依赖时，就不会重复初始化了！ 比如 当 Spring 创建 A 之后，发现 A 依赖了 B ，又去创建 B，B 依赖了 A ，又去创建 A； 在 B 创建 A 的时候，那么此时 A 就发生了循环依赖，由于 A 此时还没有初始化完成，因此在 一二级缓存 中肯定没有 A； 那么此时就去三级缓存中调用 getObject() 方法去获取 A 的 前期暴露的对象 ，也就是调用上边加入的 getEarlyBeanReference() 方法，生成一个 A 的 前期暴露对象； 然后就将这个 ObjectFactory 从三级缓存中移除，并且将前期暴露对象放入到二级缓存中，那么 B 就将这个前期暴露对象注入到依赖，来支持循环依赖。 二级缓存不行吗两种动态代理及各自优缺点jdk： 优点：是原生jdk的，不需要其他依赖；通过反射生成代理类，速度比cglib操纵字节码快 缺点：被代理类必须实现了接口；无法为没有在接口中定义的方法代理；执行代理方法时通过反射机制回调，方法执行效率低 cglib 优点：被代理类无需实现接口，因为cglib生成的代理类直接继承自被代理类；代理类能代理所有能被子类重写的方法；方法执行效率高于jdk的动态代理； 缺点：如果被代理类是final类，则无法代理；无法对final方法或private方法代理；生成代理类的方法是操作字节码文件，所以生成字节码文件的速度比jdk慢 Spring 中用到了那些设计模式工厂模式 单例模式 代理模式 观察者模式 适配器模式 装饰器模式 mybatis缓存一级缓存的作用域是同一个SqlSession，在同一个SqlSession中两次执行相同的sql语句，第一次执行完毕会将数据库查询的数据写到缓存（内存），第二次会从缓存中获取数据而不进行数据库查询，大大提高了查询效率。当一个SqlSession结束后该SqlSession中的一级缓存也就不存在了。MyBtais默认启动以及缓存。 二级缓存是多个SqlSession共享的，其作用域是mapper的同一个namespace，不同的sqlSession两次执行相同namespace下的sql语句且向sql中传递的参数也相同时，第一次执行完毕会将数据库中查询到的数据写到缓存（内存），第二次会直接从缓存中获取，从而提高了查询效率。MyBatis默认不开启二级缓存，需要在MyBtais全局配置文件中进行setting配置开启二级缓存。 MySQL为什么不用平衡二叉树作为主键索引平衡二叉树在插入删除时要保持树的平衡，需要进行旋转操作，会使性能下降； 平衡二叉树的树高、磁盘io次数多，检索速度慢； B+树叶子节点通过双向链表相连接、范围查找非常高效 有索引字段A，查询A&#x3D;1的执行流程server层的优化器选择是否通过索引查询、如果不通过则全表扫描找到符合条件的结果列； 如果通过索引，则从B+树的根节点开始，依次访问索引节点直至叶子节点，找到符合条件的索引键值，，获得该行的行指针。 通过主键索引找到该行的行记录 两个索引还是联合索引什么是幻读在同一个事务中、前后两次查询相同范围时查到的数据条数不一样 MySQL如何解决幻读的当前读加间隙锁、快照读通过MVCC 主从复制的原理MySQL主从复制的核心是二进制日志、其记录了所有的DDL和DML； 具体的主从同步过程是： Master主库在事务提交时将数据变更记录在binlog中，从库读取主库的binlog，写入到从库的中继日志relay log中。slave从库读取数据写入到自己 的数据库 如何定位慢查询开启慢查询日志 show profiles sql执行的很慢、如何优化聚合查询、多表查询、表数据量过大、深度分页 用explain查看这条sql的执行情况、通过key和key-len查看是否命中了索引； 通过type字段查看sql是否有进一步的优化空间，是否存在全索引扫描或全盘扫描； 通过extra观察是否出现了回表，如果出现则增加索引或减少返回字段 explain列possibility keys、 keys、len、extra、select-type（简单表、子查询、联合查询）、type 谈谈sql优化表的设计优化、索引优化、sql语句优化、主从复制，读写分离、分库分表 MySQL如何保证ACIDB树 vs B+树存储数据、叶子节点、查询稳定性、io次数 什么是readViewRead View（读取视图）是多版本并发控制（MVCC）中用于实现事务隔离的一种机制。它允许事务在执行读取操作时看到一致的数据快照，从而确保事务可以在其生命周期内查看到一致的视图，避免与其他事务的干扰 索引失效情况or左是索引右不是会失效； in取值范围大时失效 什么是索引下推它的核心思想是将一些过滤操作推到索引扫描的阶段，而不是在获取所有数据后再进行过滤，从而减少需要读取的数据量并提高查询效率。 binlog、redolog、undolog的写入顺序切换隔离级别12345678910111213SELECT @@session.transaction_isolation;SELECT @@Global.transaction_isolation;-- 当前修改-- 设置成可重复读SET SESSION transaction isolation LEVEL REPEATABLE READ;-- 全局修改-- 读已提交SET GLOBAL TRANSACTION ISOLATION LEVEL READ COMMITTED;-- 读未提交SET GLOBAL TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;-- 串行化SET GLOBAL TRANSACTION ISOLATION LEVEL SERIALIZABLE; 最左前缀法则是查询从复合索引的最左列开始， 并且不跳过索引中的列。如果跳跃某一列，索引将会部分失效(后面的字段索引失效)。 索引失效不符合最左前缀法则、头部模糊查询、对索引字段进行函数运算、字符串不加引号发生隐式转换、 用or连接，有一个字段没有索引则失效 in、not in使用不当（in 在结果集 大于 30%的时候索引失效）、MySQL认为全表扫描更快时； 三个日志binlogredologundologMySQL主从同步原理主要涉及到三个线程、主节点：log dump。从节点：io线程、sql线程 主节点通过log dump线程给从库io线程传输binlog数据。从库的io线程将得到的binlog写入本地的realy log中 sql线程读取relay log的日志并解析成sql执行 行锁升级表锁行锁是对索引加的锁、无索引时行锁升级为表锁（mysql进阶篇-p103） 行级锁退化索引上的等值查询(唯一索引)，给不存在的记录加锁时, 优化为间隙锁 。 索引上的等值查询(非唯一普通索引)，向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁。 索引上的范围查询(唯一索引)–会访问到不满足条件的第一个值为止。 Redis热key如何解决Redis优点支持高并发、数据结构丰富、支持多种语言、支持持久化、性能高、高可用、分布式 redis是一个kv数据库，redis底层如何实现快速根据key查出value的redis底层用哈希表来存储所有的键值对，在理想情况下查找元素的时间复杂度为O（1），另外，redis使用高效的哈希函数和渐进式哈希避免影响哈希表的性能 ClickHouseESes的倒排索引es的写入数据工作原理es的查询数据工作原理KafkaKafka的几个概念Kafka如何保证消息不丢失[11 无消息丢失配置怎么实现？](file:&#x2F;&#x2F;&#x2F;C:&#x2F;Users&#x2F;123z’l’q&#x2F;Desktop&#x2F;jike&#x2F;html&#x2F;Kafka核心技术与实战&#x2F;11 无消息丢失配置怎么实现？.html) Kafka保证消息顺序消费Kafka保证消息有序分区：消息在同一分区内的顺序是保证的。 消息键：使用相同的键发送消息可以确保它们被分配到相同的分区。 消费者顺序处理：消费者读取同一分区的消息会保持顺序。 事务：事务可以确保消息的准确一次传递，并保持顺序性。 副本和一致性：副本机制和数据一致性增强了消息的可靠性。 Kafka实现多线程消费Kafka如何解决重复消费Kafka的架构Kafka为什么快Kafka快通常指的是高效移动大量数据的能力 1、顺序磁盘io 2、零拷贝 Kafka幂等性如何处理消息挤压流量突然增大怎么办Kafka的使用场景Kafka对比其他MQKafka时间轮片Kafka为什么快Kafka零拷贝如何实现Kafka的keyKafka的多副本机制Kafka主从复制消费者和消费者组Kafka基础架构Kafka的传播关系Kafka启动命令Kafka偏移量维护在哪Kafka单个节点能不能并发消费kafka一个分区可以被一个消费者组内多少不同消费者消费一个消费者可以同时消费多个topic吗？Kafka同一主题不同分区之间是否有序分布式分布式锁zookeeper 实习项目个人文件库为什么要分片，如何分片？如何实现预览如何实现视频编码转换秒传如何实现多级目录如何实现和删除如何实现断点续传恶意上传大文件怎么办如何压缩文件1000QPS压测介绍每秒1000QPS10w个对象需要存到ck数据库 先把请求数据放到Kafka的不同分区和主题中（2个主题、100个分区），然后消费者（10个）监听到消息后放到redis读队列中，有两个衡量指标衡量是否转存到写队列。一个是数量阈值、一个是时间。如果写队列到了一定阈值（1w）后、将读队列开关关闭、转存到读队列（while循环不断检测）。如果没到阈值但到时间了也转存到读队列。之后从读队列中拿出数据序列化并基于jdbc存到ck，开关打开。都没有的话则休眠10ms后再自旋 阈值：8000 时间阈值：0.15s 阈值的设定：while中判断是否达到阈值、然后拿出所有的转到读队列。阈值一方面和ck的批量写入量有关，另一个是和判断后的时间间隙有关 经实验、ck批量写入是1w、判断后又有大约2000的数据进来。 时间阈值：100ms大约1w个对象、可能没到8000阈值（需要80ms）、经实验150ms内堆积也差不多8000个对象 为什么原生jdbc避免将Java对象转成数据库中的行，减少ORM时的开销；另外，mysql的批量写入一次最多4M数据（可设置），估算每一次请求的数据大概是5kb、5000字节、也就是说，mp的批量写入一次最多写入800条数据、再多就会一条一条写入。 而ck官方建议：如果是1kb，则写入速度是5w到20w每秒；（当时测试写入1kb的5w数据大概是900多毫秒、2kb大概是1700多ms）所以批量写入的阈值设为了1w 双buffer缓冲队列原因： 隔离数据处理和数据写入。提高系统吞吐量和处理效率； 避免并发冲突，当写队列接收时读队列转存到数据库，不会相互干扰 为了保证批量写入，如果只有一个队列的话 介绍：两个set、一个用作读、一个用作写。 如何保证批量插入用了双buffer缓存队列，引入了redis作为缓存。 Kafka的消费者和topic和分区如何配的生产者的ack参数设为了1、消费者手动提交偏移量 消费者幂等性如何保证转入到redis的写队列时、用set作为数据结构自动去重 MySQL VS ClickHouse MySQL是OLTP在线事务处理型数据库，ck是OLAP在线分析处理型数据库； MySQL支持事务，适合对数据一致性较高的场景，ck不支持事务； MySQL单行写入快，批量写入较慢，ck单行慢，批量快； MySQL是行式存储，ck是列式存储； MySQL适合较小的数据查询，ck适合较大的数据查询 ； MySQL适合强一致性、复杂事务处理和高并发读写的场景，比如传统的业务系统，关系型事务存储； ck适合高吞吐量，大规模数据分析和复杂查询的场景，比如数据分析，日志分析，业务数据报表 为什么用ck数据库Java实体属性多、数据库表中列多；数据量大，以相当大的批次插入，写入快；数据不需要更新；存储成本低；不需要事务 为什么用Kafka持久化能力强大、高吞吐量和高可扩展性、支持多个消费者组并行处理信息；作为数据缓冲 数据库连接池如何配置Kafka保证消息的顺序性1、分区机制。Kafka的一个topic可被分成多个partition，消息在发布时追加到特定分区，每个消息内部，消息是按照追加的顺序来存储的，因此保证了分区内的消息顺序性 2、分区器。生产者在发送消息时可以指定分区器来决定消息发送到哪个分区，分区器通常基于消息的某个属性来决定的，因此具有相容key的消息会被发送到一个分区； 3、消息key 4、消费者组配置。在消费者组中，每个分区通常被一个消费者示例消费，按顺序消费 5、副本同步。每个分区有多个副本，一个是leader，其他是follower，当生产者发送消息时先写入leader副本然后leader追加到follower副本，只有当leader和follower都收到确认消息后生产者才认为消息发送成功。 为什么用xxl-job而不是@Schedulexxl-job有web管理界面，能够观察日志和错误信息，方便问题排查； xxl-job有失败重试（配置最大重试次数为3，间隔为1分钟、如果3次插入到数据库都失败则人为干涉）、报警处理； 考虑到该系统的扩展性，以后随着业务qps的增加，可能会在分布式环境下运行 自定义表单RBAC权限模型介绍安全原则优缺点四种模型SQLABAC敏感词、敏感图片过滤个人项目秒杀如何实现秒杀主要解决两个问题，一个是超卖一个是超买 超卖：乐观锁，update时用where判断count&gt;0 超买：一个用户抢购了多份。基于redisson分布式锁和lua脚本 超买一开始基于redis的setnx自己实现了分布式锁，key为用户id，value为线程标识，释放时判断持有锁的线程是否是当前线程然后去删除锁 为什么value是线程标识：防止误删别人的锁。比如线程1执行是发生了阻塞然后到期释放锁，线程2拿到了锁，此时线程1活了删除了线程2的锁 基于redisson主要是为了解决锁超时、自动续期、不可重入、主从一致性（ 如果Redis提供了主从集群，当我们向集群写数据时，主机需要异步的将数据同步给从机，而万一在同步过去之前，主机宕机了，就会出现死锁问题。）的问题 基于lua主要为了解决原子性问题，当释放锁时先判断当前持有锁的线程是否是当前线程，如果是则删除。当线程1判断确实是自己的锁时如果锁过期了线程2拿到了锁，但此时线程1执行了删除命令，此时线程2的锁被删除。而lua是将这些判断删除操作以原子操作的方式执行，保证了不会误删锁。 redisson的使用：redissonClient的getLock方法，参数是用户id。使用tryLock(获取锁的最大等待时间，锁超时释放时间，时间单位) 一开始是setnx+lua，后来是redisson，底层也是基于lua 订单重复提交和超市释放分布式锁特点可见性、互斥性、高可用、高性能、安全性 Redisson底层原理可重入+自动续期+锁重试+互斥 可重入：通过hash结构，key、hashKey为线程标识，value为锁的持有个数。每次获取锁时先看是否是当前线程、如果是则value+1并续期，否则等待 自动续期：通过watchDog来实现：每10秒观测一次当前线程是否执行完成、如果没有则默认续期30s 主从一致性：MutiLock。获取锁时会写入所有的主从节点，每个节点地位一样，只有所有的节点都写入成功则视作获取成功。具体是redisson将多个锁放到一个集合里，然后通过while循环不断去尝试拿锁，有一个总的加锁时间，是加锁个数*1500ms，如果在这时间内都加锁成功才算是成功，否则会再去尝试 缓存大流量商品的问题存在缓存穿透和缓存击穿的问题 基于redisson的bloom filter解决缓存穿透问题， 创建布隆过滤器，设置初始最大容量和误判率0.1%，把商品信息加载到布隆过滤器。误判率低则需要更大的位数组和更多哈希函数、占用更多内存资源。高则命中率低对数据库压力大 IP黑名单如何实现什么情况下拉黑IP、如何实现一天之内发5篇违规文章或每秒超过100QPS将该用户IP放入redis黑名单，时长为3天 基于拦截器：每次请求前判断redis是否存在该IP的key、存在则限流 Redis+Lua限流ES vs MySQLES和数据库如何同步布隆过滤器如何实现的基于位数组和哈希函数来实现、插入元素时通过哈希函数计算对应的位数组的位置并设为1，当判断元素是否存在时计算其对应的哈希，如果为0则不存在，如果为1则可能存在 隆过滤器误差率怎么去设置，如果我想降低他的误差率有哪些办法增加哈希函数个数、合理设计哈希函数、增大位数组长度、 介绍DFA确定性有穷算法，通常有组成部分：状态集，字母表，转移函数，初始状态，接受状态 1. 确定性有限自动机（DFA）的定义确定性有限自动机是一个有限状态机，其在每个状态下对于每个输入符号都有且仅有一个转移状态。DFA 的关键特点是： 状态有限：DFA 的状态数量是有限的。 确定性：对于每个状态和每个输入符号，DFA 只有一个确定的下一个状态。 接受状态：DFA 中的某些状态被标记为接受状态（或终止状态），如果 DFA 在输入字符串处理完毕后处于接受状态，则该字符串被接受。 2. DFA 的组成部分一个 DFA 通常由以下五个部分组成： 状态集合（Q）：有限个状态的集合。 输入符号集合（Σ）：有限个输入符号的集合，称为字母表。 转移函数（δ）：状态转移函数，定义了在给定状态和输入符号下的转移规则。形式上，δ: Q × Σ → Q。 初始状态（q0）：DFA 的起始状态，q0 ∈ Q。 接受状态集合（F）：接受状态的集合，F ⊆ Q。 3. DFA 的工作流程 初始化：从初始状态开始。 读取输入：逐个读取输入字符串中的符号。 状态转移：根据当前状态和输入符号，使用转移函数 δ 确定下一个状态。 结束：处理完所有输入符号后，如果 DFA 处于接受状态，则输入字符串被接受，否则被拒绝。 如何完成热词的统计通过ik分词器将查询内容分词后以zset的格式保存到redis、启动一个定时任务一小时一次刷新redis到数据库并清理数据 另外启动定时任务每天0点启动，统计当天排行前十的数据到数据库并清除redis redis结构：key为hotword：day&#x2F;month score为出现次数 member为词条 表结构：词条、次数、日期、排名、标识（小时、天） 为什么不设置TTL：防止定时任务未统计完成数据丢失 CompletableFuture如何使用私聊功能如何实现加好友：follow表，用户id，粉丝id 涉及到的表？ 聊天数据保存在哪？WebSocket vs httpwebsocket是全双工通信，客户端服务端可以互相主动发消息，实时性更强 http是单向协议，虽然是基于全双工的TCP的，服务器不能主动发送到客户端 ws缺点：对网络要求更高，需要处理好重连机制 商品数量数据一致性如何保证如何基于ES完成文章的检索Feed流推送介绍一下Feed流产品有两种常见模式：Timeline：不做内容筛选，简单的按照内容发布时间排序，常用于好友或关注。例如朋友圈 优点：信息全面，不会有缺失。并且实现也相对简单 缺点：信息噪音较多，用户不一定感兴趣，内容获取效率低 智能排序：利用智能算法屏蔽掉违规的、用户不感兴趣的内容。推送用户感兴趣信息来吸引用户 优点：投喂用户感兴趣信息，用户粘度很高，容易沉迷 缺点：如果算法不精准，可能起到反作用本例中的个人页面，是基于关注的好友来做Feed流，因此采用Timeline的模式。该模式的实现方案有三种： timeline大致可分为三类：推模式，拉模式，推拉结合 推模式即发文时把文章推送给所有粉丝，优点是读取快 缺点推送慢且占用空间 拉模式即粉丝读取时遍历关注的博主然后把信息拉取过来。优点是节约空间，查看时才拉取信息，缺点是有读取延迟，如果用户关注了很多博主同一时刻拉会给服务器造成压力 推拉结合即只把feed流推送给活跃粉丝，不活跃粉丝只有查看时才使用拉模式获取信息 实现逻辑是发文时在保存到数据库后推送文章到粉丝的收件箱，使用redis的zset来保存，zset的key为粉丝id，score为时间戳+文章id，value为发文id 为什么要这么设计zset结构：score为时间戳的原因是当用户查看关注博主的发文时会调用分页查询接口，传统的分页查询会存在重复查询的问题，使用时间戳作为score可以实现：每次查询时携带上一次查询的时间戳和偏移量，这样就可以实现无重复查询。score加上文章id为了防止时间戳重复 ——————————用户标签的实现、其他方式用MySQL存储、有多少标签就有多少字段、如果新增标签的话会新增字段 用MySQL配合二进制实现。预设1个long类型字段、有8*8个位、可表示64个标签 取消标签：取反~后&amp; 新增标签：该表字符值 | tag 场景给你一个正整数，求这个正整数二进制有几个1-将该数与1进行与运算、结果为1则加1.该数右移一位直至为0 12345678910def count_set_bits(n): count = 0 while n: count += n &amp; 1 n &gt;&gt;= 1 return count# 示例调用number = 13 # 二进制表示为 1101print(count_set_bits(number)) # 输出应该是 3 自我介绍个人优势、实习经历、项目经历、表达意愿 · 对接前端人员共同完成CMS的迭代、协助测试人员解决bug，进行系统调优 反问学习建议、方式； 对应届生来说、广度和深度哪个更重要","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"https://se-daming.github.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"second","slug":"second","date":"2024-10-13T07:58:22.000Z","updated":"2024-10-13T07:58:22.273Z","comments":true,"path":"2024/10/13/second/","permalink":"https://se-daming.github.io/2024/10/13/second/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"second333","slug":"first-blog","date":"2024-10-13T07:58:22.000Z","updated":"2024-10-13T08:22:36.878Z","comments":true,"path":"2024/10/13/first-blog/","permalink":"https://se-daming.github.io/2024/10/13/first-blog/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"this is title","slug":"hello-world","date":"2024-10-13T07:20:34.452Z","updated":"2024-10-13T07:51:15.586Z","comments":true,"path":"2024/10/13/hello-world/","permalink":"https://se-daming.github.io/2024/10/13/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"https://se-daming.github.io/tags/%E9%9D%A2%E8%AF%95/"}]}