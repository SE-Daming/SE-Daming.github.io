[{"title":"Kafka如何调优？","date":"2024-10-19T08:00:04.000Z","path":"2024/10/19/Kafka如何调优？/","text":"","tags":[]},{"title":"Kafka中消费者事务是什么？","date":"2024-10-19T07:59:48.000Z","path":"2024/10/19/Kafka中消费者事务是什么？/","text":"","tags":[]},{"title":"Kafka中leader的选举流程是怎样的","date":"2024-10-19T07:59:34.000Z","path":"2024/10/19/Kafka中leader的选举流程是怎样的/","text":"","tags":[]},{"title":"Kafka消息挤压了，怎么办","date":"2024-10-19T07:58:59.000Z","path":"2024/10/19/Kafka消息挤压了，怎么办/","text":"消息积压的原因生产快消费慢解决方案1、增加主题的分区数，同时增加消费者数，扩展消费者组 2、提高消费者每次从服务端拉取的字节数fetch.max.bytes（默认是50M）、每次拉取的最大条数max.poll.records。（达到这俩参数的其中一个就会拉取停止） 3、优化消费者处理逻辑 4、生产者限流 5、持续监控Kafka集群，比如用eagle","tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://se-daming.github.io/tags/Kafka/"}]},{"title":"Kafka消息重复","date":"2024-10-19T07:53:50.000Z","path":"2024/10/19/Kafka消息重复/","text":"生产者重复acks设为-1时，leader收到消息后ISR同步了消息，此时leader还未返回ack宕机了。生产者认为broker没有收到消息会重复发送消息给broker中的新选举的leader 消费者重复设置手动提交offset时可能出现重复消费","tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://se-daming.github.io/tags/Kafka/"}]},{"title":"Kafka如何保证消息可靠性","date":"2024-10-19T07:40:20.000Z","path":"2024/10/19/Kafka如何保证消息可靠性/","text":"broker多副本机制每个分区可以有多个副本，这些副本分为一个leader和多个follower，当leader故障时，会从follower中选举出新的leader，增加了数据可用性 确认机制可以设置三种不同的确认级别acks acks&#x3D;0：消息发送到分区时不需要等待确认akcs&#x3D;1：消息发送到分区后只需leader确认acks&#x3D;ALL：消息发送到分区后leader和follower都需要确认消息持久性Kafka会将消息持久化到磁盘，其中每一个分区对应于一个磁盘文件，确保系统故障或重启时不会丢失数据 生产者发送消息时，selector从NetworkClient中取出发送请求后发送给broker，发送成功则等待broker的应答acks，发送失败会重试 消费者消费者消费时可以设置手动提交offset，确保消息不会丢失","tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://se-daming.github.io/tags/Kafka/"}]},{"title":"Kafka如何保证消息顺序性","date":"2024-10-19T07:14:37.000Z","path":"2024/10/19/Kafka如何保证消息顺序性/","text":"为什么保证顺序性创建订单，订单支付是两个顺序的操作 如何保证顺序性生产顺序性在同一个分区内，消息是追加写到文件末尾的，可以保证消息写的顺序性 如果希望某一类消息有序，通过设置指定key&#x2F;partition使消息发送到同一个partition中，然后指定一个消费者来消费,保证生产的顺序性 消费顺序性每次消费时都会从上次的offset处消费，能够保证消费的顺序性； 每一个分区只能由一个消费者消费，保证顺序性 消息发送重试时发送顺序如果创建订单发送失败，订单支付发送成功，这样也会导致顺序性失效 1: Kafka中有个max.in.flight.requests.per.connection的参数,设为1，它告诉生产者在收到服务端响应之前只能发送一条消息，但会降低吞吐量 2: enable.idempotence&#x3D;true 开启生产者幂等性，原理与producer id和Sequence Number两个参数有关","tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://se-daming.github.io/tags/Kafka/"}]},{"title":"索引下推（ICP）是什么","date":"2024-10-18T14:22:22.000Z","path":"2024/10/18/索引下推是什么/","text":"索引下推是什么索引优化功能，允许存储引擎在索引遍历过程中执行where的条件，直接 过滤掉不满足条件的结果从而减少回表次数，提高查询效率。 它就是为了减少回表次数的 索引下推原理select * from stu where name&#x3D;’zhangsan’ and age&#x3D;18 （name，age是联合索引） MySQL架构可简单分为server层和存储引擎层， 当没有索引下推时，存储引擎层查询到name是张三的id后根据这些id进行回表，需要回表多次，然后把全部的记录返回给server进行筛选 有索引下推时，存储引擎层查询到name是张三的id并且去过滤掉age是18的，然后回表后把数据返回server 没有ICP 有ICP","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://se-daming.github.io/tags/MySQL/"}]},{"title":"Redis渐进式哈希","date":"2024-10-18T13:37:06.000Z","path":"2024/10/18/Redis渐进式哈希/","text":"Redis底层是使用dict存储数据的，包含主、备用两个哈希表，当数据量达到一定时会触发rehash重新调整，每次处理请求时会把主哈希表的数据迁移部分到备用哈希表，这叫Rehash。 因为一次rehash会导致短暂的服务中断，所以分多次来实现。叫做渐进式哈希 Rahash涉及到ReHashIdx，初始值为-1，每次处理请求会加1并把主哈希表对应位置的元素迁移到备用哈希表。 在此过程中，如果操作元素key大于ReHashIdx则访问旧哈希表，否则访问新哈希表","tags":[{"name":"Redis","slug":"Redis","permalink":"https://se-daming.github.io/tags/Redis/"}]},{"title":"快手","date":"2024-10-18T10:58:35.000Z","path":"2024/10/18/快手-1/","text":"mysql 三大日志redolog：保证数据持久性 undolog：事务异常的回退、MVCC的版本链 binlog:做数据备份和主从同步 其中binlog的底层数据结构说一下分别细说三大日志的作用幻读概念mysql的隔离级别mysql inodb的数据结构B+树和B树有啥区别（为啥比B树快）索引下推知道吗voliate关键字有什么作用详细说一下JMM内存模型voliate关键字为啥不能保证原子性","tags":[{"name":"快手日常","slug":"快手日常","permalink":"https://se-daming.github.io/tags/%E5%BF%AB%E6%89%8B%E6%97%A5%E5%B8%B8/"}]},{"title":"JVM内存区域","date":"2024-10-18T09:43:19.000Z","path":"2024/10/18/JVM内存区域/","text":"","tags":[]},{"title":"JMM到底是什么","date":"2024-10-18T08:02:35.000Z","path":"2024/10/18/JMM到底是什么/","text":"","tags":[]},{"title":"Java优先队列","date":"2024-10-18T04:44:59.000Z","path":"2024/10/18/Java优先队列/","text":"PriorityQueue123456789101112131415161718192021pq.poll();pq.offer();//队列满返回falsepq.add();//队列满抛异常PriorityQueue&lt;String&gt; pq = new PriorityQueue&lt;&gt;(new Comparator&lt;String&gt;() &#123; @Override public int compare(String s1, String s2) &#123; return Integer.compare(s1.length(), s2.length()); // 按长度升序 &#125;&#125;);// 添加元素pq.add(&quot;ale&quot;);pq.add(&quot;banana&quot;);pq.add(&quot;kiwi&quot;);pq.add(&quot;grape&quot;);// 打印并移除元素，按长度优先级while (!pq.isEmpty()) &#123; System.out.println(pq.poll()); // 输出 ale,kiwi, grape,banana&#125;","tags":[{"name":"集合","slug":"集合","permalink":"https://se-daming.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"volatile浅析","date":"2024-10-18T03:58:24.000Z","path":"2024/10/18/volatile浅析/","text":"volatile作用保证可见性、禁止指令重排 可见性原理指示JVM使用这个变量时去主存中获取 具体些说：每一个线程都有自己的本地内存，线程间共享主内存。 volatile内存可见性主要通过lock前缀指令实现，它会锁定当前内存区域的缓存，并且立即将当前缓存行写入到主内存，会写主内存的时候通过MESI协议使其他线程缓存的改变量失效，导致其他线程也要去主内存去重新读取 有序性原理插入特定的内存屏障禁止指令重排序 volatile 的有序性是通过插入内存屏障（Memory Barrier），在内存屏障前后禁止重排序优化，以此实现有序性的。 什么是内存屏障？内存屏障（Memory Barrier 或 Memory Fence）是一种硬件级别的同步操作，它强制处理器按照特定顺序执行内存访问操作，确保内存操作的顺序性，阻止编译器和 CPU 对内存操作进行不必要的重排序。内存屏障可以确保跨越屏障的读写操作不会交叉进行，以此维持程序的内存一致性模型。 在 Java 内存模型（JMM）中，volatile 关键字用于修饰变量时，能够保证该变量的可见性和有序性。关于有序性，volatile 通过内存屏障的插入来实现： 写内存屏障（Store Barrier &#x2F; Write Barrier）： 当线程写入 volatile 变量时，JMM 会在写操作前插入 StoreStore 屏障，确保在这次写操作之前的所有普通写操作都已完成。接着在写操作后插入 StoreLoad 屏障，强制所有后来的读写操作都在此次写操作完成之后执行，这就确保了其他线程能立即看到 volatile 变量的最新值。 读内存屏障（Load Barrier &#x2F; Read Barrier）： 当线程读取 volatile 变量时，JMM 会在读操作前插入 LoadLoad 屏障，确保在此次读操作之前的所有读操作都已完成。而在读操作后插入 LoadStore 屏障，防止在此次读操作之后的写操作被重排序到读操作之前，这样就确保了对 volatile 变量的读取总是能看到之前对同一变量或其他相关变量的写入结果。 通过这种方式，volatile 关键字有效地实现了内存操作的顺序性，从而保证了多线程环境下对 volatile 变量的操作遵循 happens-before 原则，确保了并发编程的正确性。 MESI协议全称为 Modified,Exclusive ，Shared,Invalid，是一种高速缓存一致性协议，为了解决CPU在并发环境下多个CPU缓存不一致而提出的 它定义个高速缓存中数据的四种状态 Modified（M）：表示缓存行已经被修改，但还没有被写回主存储器。在这种状态下，只有一个 CPU 能独占这个修改状态。 Exclusive（E）：表示缓存行与主存储器相同，并且是主存储器的唯一拷贝。这种状态下，只有一个 CPU 能独占这个状态。 Shared（S）：表示此高速缓存行可能存储在计算机的其他高速缓存中，并且与主存储器匹配。在这种状态下，各个 CPU 可以并发的对这个数据进行读取，但都不能进行写操作。 Invalid（I）：表示此缓存行无效或已过期，不能使用。 MESI 协议的主要用途是确保在多个 CPU 共享内存时，各个 CPU 的缓存数据能够保持一致性。当某个 CPU 对共享数据进行修改时，它会将这个数据的状态从 S（共享）或 E（独占）状态转变为 M（修改）状态，并等待适当的时机将这个修改写回主存储器。同时，它会向其他 CPU 广播一个“无效消息”，使得其他 CPU 将自己缓存中对应的数据状态转变为I（无效）状态，从而在下次访问这个数据时能够从主存储器或其他 CPU 的缓存中重新获取正确的数据。","tags":[{"name":"JUC","slug":"JUC","permalink":"https://se-daming.github.io/tags/JUC/"}]},{"title":"MySQL索引高度计算","date":"2024-10-18T02:53:45.000Z","path":"2024/10/18/MySQL索引高度计算/","text":"B+树三层就可存储千万级别数据 以聚集索引为例MySQL 是以页的形式组织数据的 若有为2层根节点存放主键和指针 设主键为bigint，8字节、指针固定6字节 一页是16k&#x2F;（8+6）&#x3D;1000，说明根节点可储存1000个指针 假设一行数据是300字节，则一个数据页16k&#x2F;300&#x3D;50条数据 1000*50&#x3D;5w数据 若为3层同样根节点存储1000个指针指向1000个数据页，每个数据页同样有1000个指针指向第三层的数据页 第三层每一个数据页50条记录 则总数据1000x1000x50&#x3D;5000w","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://se-daming.github.io/tags/MySQL/"}]},{"title":"快手","date":"2024-10-17T15:39:22.000Z","path":"2024/10/17/快手/","text":"1.mysql索引为什么要使用b+树，而不使用b树、AVL为什么不用B树B树的所有节点既存放k也有value，B+树只有叶子节点，非只有k B树的叶子节点是独立的，B+树叶子节点间通过链表连接 B树检索时可能没到叶子节点就结束了，B+树的效率很稳定 范围查找时B树找到下限后进行中序遍历然后找上线，B+树只需遍历链表 B+树层高一般3-4层就可存储千万数据，磁盘io最多也3，4次。 综合：B+树更少的io次数，更高效的查询效率，更适合范围查询 为什么不用AVLAVL每个节点只保存一个数据，磁盘io次数更多 AVL需要旋转来保持平衡，效率低下 2.为什么千万级别的数据b+树只需要三到四层？（具体的计算过程忘记了，这个问题是上个问题自己引出来的，长记性：不要给自己挖坑）3.最左匹配原则：联合索引（a，b，c，d），判断各个条件下走索引的情况：a&#x3D;1 and b &#x3D; 2 and d &#x3D; 3 and c &#x3D;4a&#x3D;1 and b &#x3D; 2 and c &gt; 1（这里说太快了，想都没想就说了，说成c不会走索引，实际应该是c会走，但d不走，这里都会犯错不该） 4.mysql事务特性以及怎么实现的？5.MVCC能保证哪个事务隔离级别（读已提交和可重复读，这里自己提了两种隔离级别read view生成时机的不同，好！）6.MVCC有哪些好处（我觉得最重要的是并发读无需加锁和隔离性吧，还有解决脏读和可重复读这些）7.java基础数据类型（平时没怎么用过byte忘记还有这个了，说应该是七种，实际是八种，我真是癫了）8.int占几个字节（4个字节，算是猜对了）9.讲讲ConcurrentHashMap（jdk1.7和jdk1.8的都说了，对比不同和提升）10.什么情况下链表会转成红黑树，红黑树什么情况下会转为链表（8和6，这里提了一下为什么是8和6，前面看过）11.concurrentHashMap的get方法是否加锁？（没有加锁，提了一下底层用来volatile来修饰value和size，保证可见性）12.那你解释一下volatile这个关键字（讲了讲可见性怎么实现的，说了一下总线嗅探，以及MESI协议）13.那你了解ArrayList和hashMap的扩容机制吗？（ArrayList很久没看了，就记得是扩为1.5倍，HashMap讲的比较详细）14.redis的多路复用有了解过吗？（不会，有了解过但忘记了，半年前看的早忘了）15.redis的分布式锁你的理解（因为我是项目中对redisson分布式锁进行封装，我觉得这种问题问你理解就是想看看你为什么要选择这种分布式锁实现方式，应该要对比redis本身的setnx的缺点，还有为什么选择redisson分布式锁，比redis原生的好在哪，我觉得问理解还可以说分布式锁的意义，总之这种题比较开放）","tags":[{"name":"快手日常","slug":"快手日常","permalink":"https://se-daming.github.io/tags/%E5%BF%AB%E6%89%8B%E6%97%A5%E5%B8%B8/"}]},{"title":"hot100","date":"2024-10-17T15:33:07.000Z","path":"2024/10/17/hot100/","text":"31 下一个排列1将nums = [1,2,7,4,3,1]变成nums = [1,3,1,2,4,7] steps： 先找出最大的索引 k 满足 nums[k] &lt; nums[k+1]，如果不存在，就翻转整个数组；再找出另一个最大索引 l 满足 nums[l] &gt; nums[k]；交换 nums[l] 和 nums[k]；最后翻转 nums[k+1:]。 12345678910111213141516171819202122232425262728293031323334353637class Solution &#123; public void nextPermutation(int[] nums) &#123; int i=nums.length-2; while(i&gt;=0)&#123; if(nums[i]&lt;nums[i+1])&#123; break; &#125; i--; &#125; if(i&lt;0)&#123; reverse(nums,0); return; &#125; int j=nums.length-1; while(j&gt;=0)&#123; if(nums[j]&gt;nums[i])&#123; break; &#125; j--; &#125; swap(nums,i,j); reverse(nums,i+1); &#125; void swap(int[]nums,int i,int j)&#123; int tmp=nums[i]; nums[i]=nums[j]; nums[j]=tmp; &#125; void reverse(int[]nums,int begin)&#123; int end=nums.length-1; while(begin&lt;end)&#123; swap(nums,begin,end); begin++; end--; &#125; &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"https://se-daming.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"基于SPI修改Sharding-JDBC实现Nacos公共配置","date":"2024-10-17T07:28:53.000Z","path":"2024/10/17/基于SPI修改Sharding-JDBC实现Nacos公共配置/","text":"","tags":[]},{"title":"双亲委派机制是什么，如何打破","date":"2024-10-17T06:25:37.000Z","path":"2024/10/17/双亲委派机制是什么，如何打破/","text":"定义双亲委派是类加载时的一种机制，主要涉及到三个加载器：启动类加载器。扩展类加载器，应用程序加载器 按顺序采取自下而上的顺序委派加载，一个类加载时首先去看应用程序加载器是否加载过、加载过则返回，没有则看扩展类是否加载过、没有则看启动类是否加载过，加载过则返回，没有则从上而下加载。启动类看是否是自己加载的范畴，是则加载并返回，不是则扩展类看是否，直到加载成功 当一个类加载器去加载某个类的时候，会自底向上查找是否加载过，如果加载过就直接返回，如果一直到最顶层的类加载器都没有加载，再由顶向下进行加载。 作用1、避免类重复加载 2、保证类加载的安全性，防止核心类库被改变 如何指定特定的加载器获取到类加载器，调用loadClass方法 如何打破双亲委派1、自定义类加载器重写loadClass方法。Tomcat是这样做的 2、线程上下文类加载器，利用上下文类加载器来加载，JDBC、JNDI 3、Osgi框架的类加载器，Osgi是一套新的类加载器机制 Tomcat是如何做的问题：一个tomcat可运行多个web应用，如果两个应用出现了相同的限定类名，如果不打破的话则不能正确加载 （在JVM中，只有相同类加载器+相同类名才视作同一个类） 做法：tomcat为每一个应用都自定义了一个类加载器去加载对应的类，主要通过该重写ClassLoader中的loadClass方法实现。 涉及到的tomcat类加载器的层次如下 每个Web应用会创建一个独立的WebApp类加载器来实现应用之间的隔离；Shared类加载器用于加载应用间共享的类比如Spring，mybatis； 通用类加载器加载可悲web应用和tomcat内部组件共享的类；Catalina用于加载tomcat自身的类 ClassLoader中四个核心方法 1234567891011public Class&lt;?&gt; loadClass(String name)类加载的入口，提供了双亲委派机制。内部会调用findClass 重要protected Class&lt;?&gt; findClass(String name)由类加载器子类实现,获取二进制数据调用defineClass ，比如URLClassLoader会根据文件路径去获取类文件中的二进制数据。重要protected final Class&lt;?&gt; defineClass(String name, byte[] b, int off, int len)做一些类名的校验，然后调用虚拟机底层的方法将字节码信息加载到虚拟机内存中protected final void resolveClass(Class&lt;?&gt; c)执行类生命周期中的连接阶段，默认是false、也就是不连接，不加载静态方法 loadClass：提供双亲委派机制，调用findClass去根据类路径获取二进制数据，","tags":[{"name":"JVM","slug":"JVM","permalink":"https://se-daming.github.io/tags/JVM/"}]},{"title":"百度","date":"2024-10-16T15:42:46.000Z","path":"2024/10/16/百度/","text":"基本数据类型 byte1 short2 int4 long8 char2 float4 double8 boolean 面向对象三大特性 封装：通过 public private default protected来实现，主要为了限制其他类和包使用 继承：一个对象可继承自另一个对象 多态：一个变量可有多种表现形态。主要由继承来实现，比如teacher和stu都继承自person，则person既可以表现成stu也可以。。。 重载重写+多态+虚方法表 重载是一个类中有多个方法方法名相同，但是参数或参数类型、返回值不同 重写是当继承自另一个类是，子类重写父类的方法 多态如何实现？ 虚方法表是多态实现的一个必要条件，它记录了方法的实现类的地址，用来确定引用变量调用子类方法时具体调用的哪个方法 集合的几个接口介绍一下，并说区别 集合包含list、set、queue三个主要接口、除此之外还有map list是可重复的一些数据、set是不可重复的数据、map是键值对类型数据的集合 list下包含arraylist、linkedlist、vector的子类实现 set包含hashset、treeset的实现 map包含hashmap、linkedhashmap、hashtable、treemap的实现 ArrayList和LinkedList的区别 底层实现不同：a是动态数组、l是链表 插入和删除效率不同：a的插入需要移动后面元素，时间复杂度是On，删除时也需要移动元素，On l的插入要先找到对应元素然后o1插入，总的来说也是on，删除同理 l更适合在头部插入元素，O1、而a是On a支持索引查找，O1、l是On 大多数情况下使用啊 HashMap一整套（数据结构，扩容） 8之前是数组+链表；8之后是数组+链表+红黑树； 扩容过程:先创建原来2倍容量的数组，然后将旧数组元素拷贝到新的数组，然后改变引用指向新的数组 JMM Volatile 是Java中的一个关键字，用来解决可见性和防止指令重排 当一个变量如果没被volatile标记、则他被修改时可能会先放到缓冲区，其他变量读到的仍然是修改前的数值。 指令重排：JVM会对class文件的命令在不影响结果的前提下进行重排序 Java的锁类型 包含公平锁、分公平锁；可重入锁，不可重入锁 主要包含sync实现的和R锁 sync对比R：非公平、可公可非；不可重入，可重入；修饰代码块、方法， 修饰代码块；自动释放，手动释放；重量、轻量；基于监视器monitor实现，基于AQS实现；R可带超时的获取尝试 AQS的非公平实现（顺便把AQS一整套说了） 线程创建方式（线程和线程体）继承thread类重写run方法；实现runnable接口的run方法；实现callable接口的call方法；线程池创建； 为什么会有线程安全多线程下对同一资源进行操作，比如对同一变量自增，需要先读取然后修改。这个过程不是原子性的，可能出现读到的相同，修改后出现问题 JVM内存模型分为线程共享和线程私有堆内存、运行时常量池；Java虚拟机栈、本地方法栈、程序计数器；字符串常量池 GC算法标记清除、标记复制、标记整理对需要清除的区域先标记再清除；会导致内存碎片问题 将内存区域分为TO、from两部分、对需要清除的区域先标记再将未标记的部分整理到to区，将from指向to；内存利用率不高 先标记需要清除的，然后将其复制到内存一侧；效率不高 垃圾回收器搭配serial，serial oldparaneel、paraneel newserial CMSg1 三色标记算法 CMS,G1CMS是老年代的回收，G1是新生代和老年代；CMS用标记清除算法，G1用标记整理算法CMS：初始标记、并发标记、最终标记、并发清除G1：初始标记、并发标记、并发标记、并发清除CMS会产生内存碎片和浮动垃圾，严重时退化成serial Springboot启动流程 MySQL索引（ACID，事务隔离，MVCC） MySQL锁用来解决并发下的问题全局锁、表级锁、行级锁表锁、元数据锁、意向锁；行锁、间隙锁、临建锁，建立在索引上的，没索引则升级为表锁 MySQL三大日志redolog、undolog、binlog重做日志，用来做崩溃后的恢复；用来事务回滚和MVCC；数据备份用的 MySQL慢SQL排查 假设慢SQL不是索引的问题，可能是哪些原因表数据量过大、考虑分表；表或查询记录被上锁；MySQL抖了一下，刷新脏页到磁盘时 InnoDB的各种特性事务、外键、行级锁、崩溃后数据恢复、mvcc 说一下项目难点，并说说怎么解决 手撕快排","tags":[{"name":"百度日常","slug":"百度日常","permalink":"https://se-daming.github.io/tags/%E7%99%BE%E5%BA%A6%E6%97%A5%E5%B8%B8/"}]},{"title":"分片上传和断点续传如何实现","date":"2024-10-16T14:25:07.000Z","path":"2024/10/16/分片上传和断点续传如何实现/","text":"j用到的技术：Redis、MD5 分片上传前端将文件分片后携带文件id、各个分片的索引，总分片数。文件MD5 后端将总分片数、已经上传的分片保存到redis。当所有分片上传完成后，后端组装这些分片并计算出MD5值验证是否组装成功。 断点续传继续上传时先查询已经上传的分片、从该分片索引处继续上传","tags":[{"name":"实习","slug":"实习","permalink":"https://se-daming.github.io/tags/%E5%AE%9E%E4%B9%A0/"}]},{"title":"Kafka的架构是怎样的","date":"2024-10-16T10:15:04.000Z","path":"2024/10/16/Kafka的架构是怎样的/","text":"角色生产者、broker、消费者、topic、partition、leader、follower、ISR、zookeeper 基本原理生产者将消息发送到broker的某个topic的某个partition中，消费者从topic中获取数据，使用zk来管理集群状态和配置。这就是基础架构 生产者发送消息主要涉及到两个线程sender和main main线程中生产者调用send方法携带消息经拦截器-分区器-序列化器到达发送缓冲区双端队列RecordAccumulator，当队列中消息量达到batch-size或linger-ms的阈值则sender线程从中拉取消息到broker。过程是拉取消息构建相应的请求到NetworkClient，最多有五个请求，selector负责从中拉取消息发送到broker的分区，等待ack应答，如果acks参数设为0则不等待应答直接返回成功，如果设为1则partition的leader需要应答，如果设为-1则leader和ISR都要应答；当selector收到成功应答后则返回成功，并且清理掉缓冲队列中的信息，否则retries重试发送给分区。 消费者消费消息采用pull拉的方式主动拉取消息，但这样可能导致没数据时陷入循环，一直返回空数据 消费者工作流程 0 消费者组","tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://se-daming.github.io/tags/Kafka/"}]},{"title":"ConcurrentHashMap解析","date":"2024-10-16T08:49:34.000Z","path":"2024/10/16/ConcurrentHashMap解析/","text":"1 ConcurrentHashMap的底层结构jdk1.7是数组链表 ，类似于HashMap数组 1.8是数组+链表+红黑树，和HashMap类似 ConcurrentHashMap如何保证线程安全jdk1.8之前包含一个Segment数组（默认是16个，创建后不可更改，最大并发是16）、每一个segment元素都是一个HashEntry数组，类似于HashMap，每一个HashEntry元素是链表 Segment继承了Reentrantlock，是一种可重入锁。每一个segment守护者一个HashEntry数组的元素，要更改元素首先要获取对应的segment锁。 也就是说、同一segment的写会阻塞，不同segment可并发执行 （get要加锁吗） jdk1.8取消了segment分段锁，采用volatile（每个node的value和next）+CAS+sync保证并发安全。 增加元素时先判断容器是否为空。为空则CAS来初始化。否则看元素位置处是否为空，为空则CAS赋值。不为空则sync后遍历赋值 数据结构和hashmap类似，由数组链表红黑树组成。只锁定当前链表或红黑树的首节点来保证并发安全。锁的粒度更小 总结：jdk1.8中通过对头节点加锁来确保线程安全。锁的粒度更小，并发量更大。 为什么要用CAS和Sync计算出该位置处为空则hash碰撞的几率低，用较少的自旋完成put；有元素说明发生了哈希碰撞，有大量线程访问或容量不够了则用悲观锁sync get操作为什么不加锁node的value和next是用volatile修饰的，可以保证可加性","tags":[{"name":"集合","slug":"集合","permalink":"https://se-daming.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"HashMap解析","date":"2024-10-16T08:11:52.000Z","path":"2024/10/16/HashMap解析/","text":"h HashMap的底层原理底层结构是数组、链表、红黑树 HashMap的put流程先看table是否为空，为空则初始化，否则则计算元素下标，如果此处没元素则直接put。如果有则看当前元素是否等于插入元素，等于则覆盖。不等于则遍历链表或红黑树来查找相同的元素，找到则覆盖，找不到则插入到红黑树或链表头部。如果是链表则看是否达到阈值8，达到8且hashmap的数组长度大于64则转换成红黑树；至此插入元素完成，然后检查负载因子是否超过阈值0.75，超过则扩容，否则执行结束 扩容过程先创建一个原数组两倍大小的新数组，将原来的引用指向新数组并更新扩容阈值，将旧数组的元素重新计算哈希码并分配到新数组中， HashMap的get流程计算出元素的索引位置，如果当前位置为null则直接返回，否则看当前元素是否等于k，等于直接返回。否则遍历链表或红黑树直到找到相同的元素；如果不存在则返回null； 为什么线程不安全1、两个线程同时put导致数据丢失。两个元素计算得到的索引一样，并且得到的新插入的位置一样，会导致覆盖其他线程的数据 2、jdk1.8前多线程下扩容会导致死循环 为什么容量是2的n次方1、方便计算索引位置。利用与运算计算代替除运算，更快速的计算出位置。但前提是容量是2的n次方 2、扩容后新数组的位置容易确定，分布比较均匀。扩容中只需判断原hash和左移一位，也就是扩大两倍的hash的与运算是0还是1，0则位置不变，1则原位置加上原容量","tags":[{"name":"集合","slug":"集合","permalink":"https://se-daming.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"索引浅析","date":"2024-10-16T07:01:21.000Z","path":"2024/10/16/索引浅析/","text":"1 索引树的高度如何计算","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://se-daming.github.io/tags/MySQL/"}]},{"title":"SQL优化的几种方式","date":"2024-10-16T06:50:38.000Z","path":"2024/10/16/SQL优化的几种方式/","text":"SQL优化插入优化1、使用批量插入 2、手动提交事务 3、主键顺序插入，减少页分裂和页合并的次数 4、大批量数据使用load命令 主键设计尽量降低主键的长度、主键应当是有序自增的、避免使用UUID或其他业务主键，如身份证、业务操作时尽量不更改主键 为什么不用UUID非递增、太长（36字符）导致占用内存大，索引树的高度大，磁盘IO次数多，性能差 查询优化查询时尽量使用索引查询 索引优化尽量使用覆盖索引、多字段排序时要遵循最左前缀法则、 深度分页延迟关联或子查询优化 group byorder by优化MySQL排序有using index和using filesort两种实现方式，要尽量优化成效率高的using index，避免额外排序 也就是说，要对排序字段创建索引并尽量使用覆盖索引；如果不可避免的出现filesort可以适当增加排序缓冲区的大小 更新优化分批更新、限制更新的行数，避免大事务； 在更新的列上有索引，避免行锁升级为表锁 删除优化大批数据删除要分批次删除，避免大事务阻塞；用LIMIT控制行数 delete和truncate区别delete是DML、truncate是DDL delete删除后可回滚、truncate不能 delete对每一行删除会记录日志，速度慢；truncate不记录，直接释放整个数据页，不支持where条件 delete删除后表的结构属性不变；truncate删除后AUTO-INCREMENT重置 explain关键字 type:连接类型。性能：NULL（select 1） &gt; system （表只有一行、系统表）&gt; const（常量查找，主键或唯一索引） &gt; eq_ref（主键或唯一索引的等值匹配） &gt; ref （非唯一索引的查找）&gt; range（根据索引查找匹配行） &gt; index（扫描整个索引而不是全表扫描） &gt; ALL（全表扫描） 除了ALL都表示用到了索引 key：实际用到的索引 possible_keys：可能用到的索引 rows ：MySQL估计需要读取的行数 extra 额外信息：using index（MySQL仅通过索引来满足查询而无需读取实际数据行）、using where、using filesort（对结果排序时如果索引不能满足则读取实际数据行然后在内存中排序）、using temporary","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://se-daming.github.io/tags/MySQL/"}]},{"title":"设计一个秒杀系统","date":"2024-10-15T04:10:16.000Z","path":"2024/10/15/设计一个秒杀系统/","text":"设计将库存信心保存到redis、利用其抗高并发的特性进行库存的查询和扣减 超卖当买多卖少时，超卖最可能发生 如果允许同一个用户购买多个，则使用redis的decr命令即可、但是会导致库存数为负数。需要在decr返回值小于0时再incr回来以确保超时订单库存回滚正常 如果只允许一个用户购买一个，也就是超买问题 超买判断用户是否购买、判断库存是否充足、扣减库存 其中第二三步redis可解决 判断是否购买放到set集合里面。 分布式环境下就不能放到set、考虑放到redis 原子性MySQL存 ：库存扣了、没有订单 Redis存：数据一致性。redis做了资格判断和扣减库存，没来得及发送到mq操作数据库就挂了","tags":[{"name":"项目","slug":"项目","permalink":"https://se-daming.github.io/tags/%E9%A1%B9%E7%9B%AE/"}]},{"title":"redis单线程，出现阻塞了怎么办","date":"2024-10-15T02:57:26.000Z","path":"2024/10/15/redis单线程，出现阻塞了怎么办/","text":"","tags":[]},{"title":"redis线程模型","date":"2024-10-15T02:20:11.000Z","path":"2024/10/15/redis线程模型/","text":"i BIO、NIO、IO多路复用、信号驱动IO、异步IOBIONIOIO多路复用selectpollepoll","tags":[{"name":"Redis","slug":"Redis","permalink":"https://se-daming.github.io/tags/Redis/"}]},{"title":"https连接是如何创建的","date":"2024-10-15T00:49:33.000Z","path":"2024/10/15/https连接是如何创建的/","text":"https握手过程hhttps在建立TCP连接后会进行TLS连接，主要涉及四次握手 客户端发送Client hello请求给服务端，携带支持的TLS版本、一个随机数、（加密）密码套件列表 服务端响应Server hello，携带确认的TLS版本，一个随机数，server端安全证书，确认的密码套件 客户端收到响应后先确认CA证书的真实性如果没问题则从证书中取出公钥然后用它加密报文发送：一个随机数、加密通信算法改变通知（表示以后的通信都用会话密钥加密）、客户端握手阶段结束。客户端根据这三个随机数计算出会话密钥 服务端收到第三个随机数后通过协商的加密算法计算出会话密钥，向客户端发送：加密算法改变通知、服务端握手结束 HTTP VS https端口不同、80 443 https在建立TCP连接轴要经过TLS&#x2F;SSL握手过程再建立http连接 https是加密传输、http是明文传输 https要额外申请CA证书","tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://se-daming.github.io/tags/HTTP/"}]},{"title":"http报文格式是怎样的","date":"2024-10-14T09:42:31.000Z","path":"2024/10/14/http报文格式是怎样的/","text":"请求报文请求行、首部行、空行、请求实体 12345GET /example.com/index.html HTTP1.1Host: www.example.comConnection:closeUser-Agent: Mozilla/5.0Accept-language:CN 响应报文状态行、首部行、空行、相应实体 12345HTTP1.1 200 OKConnection:closeLast-Modified: Tue,18 Aug 2020Cotent-Length:6123Cotent-Type:text/html Connection字段是什么发送完该消息后关闭TCP连接","tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://se-daming.github.io/tags/HTTP/"}]},{"title":"http2相对于http1.1到底有哪些改变","date":"2024-10-14T07:58:01.000Z","path":"2024/10/14/http2相对于http1-1到底有哪些改变/","text":"HTTP2的目的减少感知时延，提高响应速度 手段经单一TCP连接使请求和响应多路复用 效果提供报文优先次序、服务器主动推送（如果没发送任何请求，只是建立了TCP连接可以主动推送吗）、首部字段压缩 HTTP1.1存在的问题 HOL 队首阻塞HTTP1使用持续TCP连接，允许经单一TCP连接请求相应一个web页面。这样每个web页面平等共享带宽，导致HOL 假如一个web页面有一个大视频对象和视频下面很多小对象，使用同一TCP连接请求、该大视频会花费很长时间，小对象被延迟了。这就是HOL队首阻塞 HTTP1.1解决HOL打开多个并行TCP连接、web页面的多个对象并行发送给浏览器 HTTP2解决HOL将每个报文分成二进制小帧，并且在同个TCP连接上交错发请求和响应报文，之后在接收端将其组装，这也是HTTP2最为重要的改进 成帧过程主要通过HTTP2的成帧子层完成.当服务器要发送HTTP响应时，该响应首先划分成帧，响应的首部字段成为一帧，报文体成为一帧。通过成帧子层该响应的帧与其他响应的帧交错经过单一TCP连接发送。当帧到达客户端时先在成帧子层组装成初始的响应报文，然后由浏览器处理。类似地、HTTP请求也划分成帧交错发送 服务器推送HTTP1.1中，服务器只是被动响应，浏览器请求什么就响应什么。HTTP2中服务器可以主动推送，即为一个请求发送多个响应，从而消除额外等待时延 首部压缩HTTP2会压缩请求头。如果发送的多个请求的请求头一样或类似。协议会消除重复的部分。这由HPACK算法实现：客户端和服务端同时维护一张头信息表，所有字段会存入这个表，生成一个索引号，以后就只发送索引号不发送字段，从而提高速度 总结HTTP2相对于HTTP1主要提高了响应性能，做了头部压缩、二进制成帧、请求响应多路复用、服务器主动推送","tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://se-daming.github.io/tags/HTTP/"}]},{"title":"first","date":"2024-10-14T03:50:05.000Z","path":"2024/10/14/first/","text":"这是我的第一篇博客，加油！haha","tags":[]}]